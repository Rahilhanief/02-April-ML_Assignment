{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1941b8-46ee-44da-af71-049d1bbb7dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGrid-search is used to find the optimal hyperparameters of a model which results in the most 'accurate' predictions.\\nCross validation works by splitting our dataset into random groups, holding one group out as the test,\\nand training the model on the remaining groups. \\nThis process is repeated for each group being held as the test group, then the average of the models is used for\\nthe resulting model.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 1 :\n",
    "\"\"\"\n",
    "Grid-search is used to find the optimal hyperparameters of a model which results in the most 'accurate' predictions.\n",
    "Cross validation works by splitting our dataset into random groups, holding one group out as the test,\n",
    "and training the model on the remaining groups. \n",
    "This process is repeated for each group being held as the test group, then the average of the models is used for\n",
    "the resulting model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b4a0b6-d6ca-4595-9494-0e4b94268bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe only difference between both the approaches is in grid search we define the combinations and do\\ntraining of the model whereas in RandomizedSearchCV the model selects the combinations randomly. \\nBoth are very effective ways of tuning the parameters that increase the model generalizability.\\nSo all the permutations of the hyper parameters will generate a huge number of models and as \\nthe data size increases the computational speed drastically drops. \\nThis is why data scientists prefer RandomizedSearchCV over GridSearchCV while dealing with huge data sets.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 2 :\n",
    "'''\n",
    "The only difference between both the approaches is in grid search we define the combinations and do\n",
    "training of the model whereas in RandomizedSearchCV the model selects the combinations randomly. \n",
    "Both are very effective ways of tuning the parameters that increase the model generalizability.\n",
    "So all the permutations of the hyper parameters will generate a huge number of models and as \n",
    "the data size increases the computational speed drastically drops. \n",
    "This is why data scientists prefer RandomizedSearchCV over GridSearchCV while dealing with huge data sets.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "299a6a25-cb44-4ae5-9c01-e55b801c0f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData leakage can be defined as: \"A scenario when ML model already has information of test data in training data,\\nbut this information would not be available at the time of prediction, called data leakage. \\nIt causes high performance while training set, but perform poorly in deployment or production.\"\\n\\nThe most fundamental example of data leakage would be if the true label of a dataset was included as\\na characteristic in the model. \\nIf this object is classified as an apple, the algorithm would learn to predict that it is an apple\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 3 :\n",
    "\"\"\"\n",
    "Data leakage can be defined as: \"A scenario when ML model already has information of test data in training data,\n",
    "but this information would not be available at the time of prediction, called data leakage. \n",
    "It causes high performance while training set, but perform poorly in deployment or production.\"\n",
    "\n",
    "The most fundamental example of data leakage would be if the true label of a dataset was included as\n",
    "a characteristic in the model. \n",
    "If this object is classified as an apple, the algorithm would learn to predict that it is an apple\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1d2abd-ccc2-4a7b-bf8c-c2b4db40f4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOne of the best ways to get rid of data leakage is to perform k-fold cross validation where \\nthe overall data is divided into k parts.\\nAfter dividing into k parts, we use each part as the cross-validation data and the remaining as training data.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 4 :\n",
    "\"\"\"\n",
    "One of the best ways to get rid of data leakage is to perform k-fold cross validation where \n",
    "the overall data is divided into k parts.\n",
    "After dividing into k parts, we use each part as the cross-validation data and the remaining as training data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e52d49-2aaa-42db-9f19-124612c4a1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA confusion matrix is a table that allows you to visualize the performance of a classification model. \\nYou can also use the information in it to calculate measures that can help you determine the usefulness of the model.\\nRows represent predicted classifications, while columns represent the true classes from the data.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 5 :\n",
    "\"\"\"\n",
    "A confusion matrix is a table that allows you to visualize the performance of a classification model. \n",
    "You can also use the information in it to calculate measures that can help you determine the usefulness of the model.\n",
    "Rows represent predicted classifications, while columns represent the true classes from the data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8294f4b6-b118-499b-bdfd-0729bd2f7f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrecision and recall are two evaluation metrics used to measure the performance of a classifier in\\nbinary and multiclass classification problems.\\nPrecision measures the accuracy of positive predictions, while recall measures the completeness of positive predictions.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"\n",
    "Precision and recall are two evaluation metrics used to measure the performance of a classifier in\n",
    "binary and multiclass classification problems.\n",
    "Precision measures the accuracy of positive predictions, while recall measures the completeness of positive predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda06000-8bf0-4414-9b43-517e9850af6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy  = TP + TN / TP + TN + FP + FN.\\nPrecision (true positives / predicted positives) = TP / TP + FP.\\nRecall (true positives / all actual positives) = TP / TP + FN\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 7 :\n",
    "\"\"\"\n",
    "Accuracy  = TP + TN / TP + TN + FP + FN.\n",
    "Precision (true positives / predicted positives) = TP / TP + FP.\n",
    "Recall (true positives / all actual positives) = TP / TP + FN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3572607-2ca9-4017-b43e-fe9886b15a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConfusion matrices can be used to calculate performance metrics for classification models.\\nOf the many performance metrics used, the most common are accuracy, precision, recall, and F1 score\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 8 :\n",
    "\"\"\"\n",
    "Confusion matrices can be used to calculate performance metrics for classification models.\n",
    "Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a6659d2-3962-4db3-926b-cfaf4dbb3d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere are some of the most common performance measures you can use from the confusion matrix. \\nAccuracy: It gives you the overall accuracy of the model, meaning the fraction of the total samples \\nthat were correctly classified by the classifier. \\nTo calculate accuracy, use the following formula: (TP+TN)/(TP+TN+FP+FN).\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 9 :\n",
    "\"\"\"\n",
    "Here are some of the most common performance measures you can use from the confusion matrix. \n",
    "Accuracy: It gives you the overall accuracy of the model, meaning the fraction of the total samples \n",
    "that were correctly classified by the classifier. \n",
    "To calculate accuracy, use the following formula: (TP+TN)/(TP+TN+FP+FN).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e4838a2-f271-4189-9cc3-809f289f1d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA confusion matrix presents a table layout of the different outcomes of the prediction and \\nresults of a classification problem and helps visualize its outcomes. \\nIt plots a table of all the predicted and actual values of a classifier.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 10 :\n",
    "\"\"\"\n",
    "A confusion matrix presents a table layout of the different outcomes of the prediction and \n",
    "results of a classification problem and helps visualize its outcomes. \n",
    "It plots a table of all the predicted and actual values of a classifier.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
